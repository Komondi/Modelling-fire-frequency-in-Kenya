---
title: "Descriptive Stats"
author: "Orero"
date: '2022-05-19'
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Script to start out the results section
library(tidyverse)
# read data
fire_clim <- read_csv('fire_data_2000-18.csv')
```

```{r}
# Find the summary stats
library(rstatix)
library(flextable)
fire_clim[,-1] %>% 
  # remove unwanted variables
  select(-month, -year, -average_temp, -mean_bright31, -mean_brightness,
         -mean_frp, -anomaly) %>% 
  get_summary_stats() %>% 
  select(-q1,-q3,-iqr,-mad,-ci,-se)
```

The overall minimum number of fires over the period (2000-2018) was 10 while the maximum number was 1661. In the period of 218 months, the mean and median are 277.13 and 155.00, respectively,  with a standard deviation of 304.91. On the other hand, the mean and median mean maximum temperatures were 29.19 and 29.29 respectively. For the mean minimum temperature, the mean was 18.17 degrees Celsius with a standard deviation of 2.14. Lastly, the mean amount of rainfall was 84.04mm with a standard deviation of 51.69.

The figures below show the time series of the four variables mentioned above.

```{r}
# number of fires
## Create a time series object
count_ts <- fire_clim |> 
  mutate(Time = paste(year,month,sep = "-")) |> 
  mutate(Time = zoo::as.yearmon(Time))

# Plot the time series
plot_count <- 
ggplot(count_ts, aes(Time, count )) +  geom_line(col = "red") +
  scale_x_continuous(breaks = seq(2000,2018,5)) + theme_bw() +
  labs(title = "a. Monthly fire frequency trend from 2000 to 2018 in Kenya")+
  ylab("Number of fires")+
  theme(plot.title = element_text(hjust = 0.5, size = 14),
        axis.title.y = element_text(size = 14),
        axis.title.x = element_text(size = 14),
        axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),
        legend.position = "none")

plot_count

```

```{r}
# max temperature

# Plot the time series
plot_max <- 
ggplot(count_ts, aes(Time, mean_max_temp)) +  geom_line( col = "brown") +
  scale_x_continuous(breaks = seq(2000,2018,5)) + theme_bw() +
  labs(title = "b. Monthly maximum temperature trend from 2000 to 2018 in Kenya")+
  ylab("Maximum temperature (\u00B0C)")+
  theme(plot.title = element_text(hjust = 0.5, size = 14),
        axis.title.y = element_text(size = 14),
        axis.title.x = element_text(size = 14),
        axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),
        legend.position = "none")
plot_max
```


```{r}
# min temperature

# Plot the time series
plot_min <- 
ggplot(count_ts, aes(Time, mean_min_temp)) +  geom_line(col = "blue") +
  scale_x_continuous(breaks = seq(2000,2018,5)) + theme_bw() +
  labs(title = "c. Monthly minimum temperature trend from 2000 to 2018 in Kenya")+
  ylab("Minimum temperature (\u00B0C)")+
  theme(plot.title = element_text(hjust = 0.5, size = 14),
        axis.title.y = element_text(size = 14),
        axis.title.x = element_text(size = 14),
        axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14),
        legend.position = "none")
plot_min
```



```{r}
# rainfall

# Plot the time series
plot_rain <- 
ggplot(count_ts, aes(Time, mean_rainfall)) +  geom_line(col = "orange") +
  scale_x_continuous(breaks = seq(2000,2018,5)) + theme_bw() +
  labs(title = "d. Monthly rainfall trend from 2000 to 2018 in Kenya")+
  ylab("Rainfall (mm)")+
  theme(plot.title = element_text(hjust = 0.5, size = 14),
        axis.title.y = element_text(size = 14),
        axis.title.x = element_text(size = 14),
        axis.text.x = element_text(size = 14),
        axis.text.y = element_text(size = 14))

plot_rain
```



```{r, fig.width=8, fig.height=8}
# Combine the plots
library(patchwork)
(plot_count + plot_max) / (plot_min + plot_rain)
```

From the above graphs, we see that all the four variables have some regular and predictable changes over time, which corresponds to seasonality.

# Simulation Results

## Scenario 1 (Theta = 1.5)

### Sample size n = 60

```{r}
# Read in the four time periods
five_a <- read_csv("./model_results_pap/five_year_1.5_metrics.csv")
# add mdtype column
five_a$model <- "NB"

five_b <- read_csv("./model_results_pap/five_year_1.5b_metrics.csv")
# add mdtype
five_b$model <- "BNB"
# combine the two
five_pnt1.5 <- rbind(five_a, five_b)
head(five_pnt1.5)
```

```{r, fig.width=8, fig.height=6}
# Long format
library(tidyr)
five_pnt1.5 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  # Plot line graphs
  ggplot(aes(y = value, x = ...1, group = model, col = model))+
  geom_line() +
  facet_wrap(~ metric, scales = "free") +
  # add theme
  theme_bw()+
  # add labels
  labs(title = "Comparing the Bayesian Negative Binomial model and the Standard Negative Binomial model",
       subtitle = "Comparison of four metrics with sample size n = 60,  \u03B8 = 1.5",
       x = "Dataset number")
```

Below is a table comparing the metrics

```{r}
library(flextable)
s1_60 <- 
five_pnt1.5 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  group_by(metric,model) %>% 
  summarise(mean_val = mean(value)) %>% 
  spread(key = model, value = mean_val) %>% 
  mutate(n = 60, theta = 1.5)

# Make table
s1_60 %>% 
  mutate_if(is.numeric,round, 2) %>% 
  regulartable()
```
NB beats BNB

### Sample size n = 120

```{r}
# Read in the four time periods
ten_a <- read_csv("./model_results_pap/ten_year_1.5_metrics.csv")
# add mdtype column
ten_a$model <- "NB"

ten_b <- read_csv("./model_results_pap/ten_year_1.5b_metrics.csv")
# add mdtype
ten_b$model <- "BNB"
# combine the two
ten_pnt1.5 <- rbind(ten_a, ten_b)
head(ten_pnt1.5)
```

```{r, fig.width=8, fig.height=6}
# Long format
library(tidyr)
ten_pnt1.5 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  # Plot line graphs
  ggplot(aes(y = value, x = ...1, group = model, col = model))+
  geom_line() +
  facet_wrap(~ metric, scales = "free") +
  # add theme
  theme_bw()+
  # add labels
  labs(title = "Comparing the Bayesian Negative Binomial model and the Standard Negative Binomial model",
       subtitle = "Comparison of four metrics with sample size n = 120,  \u03B8 = 1.5",
       x = "Dataset number")
```

Below is a table comparing the metrics

```{r}
library(flextable)
s1_120 <- 
ten_pnt1.5 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  group_by(metric,model) %>% 
  summarise(mean_val = mean(value)) %>% 
  spread(key = model, value = mean_val)  %>% 
  mutate(n = 120, theta = 1.5)
# make table
s1_120 %>% 
  mutate_if(is.numeric,round, 2) %>% 
  regulartable()
```

NB beats BNB

### Sample size n = 240

```{r}
# Read in the four time periods
twenty_a <- read_csv("./model_results_pap/twenty_year_1.5_metrics.csv")
# add mdtype column
twenty_a$model <- "NB"

twenty_b <- read_csv("./model_results_pap/twenty_year_1.5b_metrics.csv")
# add mdtype
twenty_b$model <- "BNB"
# combine the two
twenty_pnt1.5 <- rbind(twenty_a, twenty_b)
head(twenty_pnt1.5)
```

```{r, fig.width=8, fig.height=6}
# Long format
library(tidyr)
twenty_pnt1.5 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  # Plot line graphs
  ggplot(aes(y = value, x = ...1, group = model, col = model))+
  geom_line() +
  facet_wrap(~ metric, scales = "free") +
  # add theme
  theme_bw()+
  # add labels
  labs(title = "Comparing the Bayesian Negative Binomial model and the Standard Negative Binomial model",
       subtitle = "Comparison of four metrics with sample size n = 240,  \u03B8 = 1.5",
       x = "Dataset number")
```

Below is a table comparing the metrics

```{r}
library(flextable)

s1_240 <- 
twenty_pnt1.5 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  group_by(metric,model) %>% 
  summarise(mean_val = mean(value)) %>% 
  spread(key = model, value = mean_val)  %>% 
  mutate(n = 240, theta = 1.5)


s1_240 %>% 
  mutate_if(is.numeric,round, 2) %>% 
  regulartable()
```

NB beats BNB

### Sample size n = 360

```{r}
# Read in the four time periods
thirty_a <- read_csv("./model_results_pap/thirty_year_1.5_metrics.csv")
# add mdtype column
thirty_a$model <- "NB"

thirty_b <- read_csv("./model_results_pap/thirty_year_1.5b_metrics.csv")
# add mdtype
thirty_b$model <- "BNB"
# combine the two
thirty_pnt1.5 <- rbind(thirty_a, thirty_b)
head(thirty_pnt1.5)
```

```{r, fig.width=8, fig.height=6}
# Long format
library(tidyr)
thirty_pnt1.5 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  # Plot line graphs
  ggplot(aes(y = value, x = ...1, group = model, col = model))+
  geom_line() +
  facet_wrap(~ metric, scales = "free") +
  # add theme
  theme_bw()+
  # add labels
  labs(title = "Comparing the Bayesian Negative Binomial model and the Standard Negative Binomial model",
       subtitle = "Comparison of four metrics with sample size n = 360,  \u03B8 = 1.5",
       x = "Dataset number")
```

Below is a table comparing the metrics

```{r}
library(flextable)
s1_360 <- 
thirty_pnt1.5 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  group_by(metric,model) %>% 
  summarise(mean_val = mean(value)) %>% 
  spread(key = model, value = mean_val)  %>% 
  mutate(n = 360, theta = 1.5)


s1_360 %>% 
  mutate_if(is.numeric,round, 2) %>% 
  regulartable()
```


## Scenario 2 (Theta = 5)

### Sample size n = 60

```{r}
# Read in the four time periods
five_a5 <- read_csv("./model_results_pap/five_year_5_metrics.csv")
# add mdtype column
five_a5$model <- "NB"

five_b5 <- read_csv("./model_results_pap/five_year_5b_metrics.csv")
# add mdtype
five_b5$model <- "BNB"
# combine the two
five_pnt5 <- rbind(five_a5, five_b5)
head(five_pnt5)
```

```{r, fig.width=8, fig.height=6}
# Long format
library(tidyr)
five_pnt5 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  # Plot line graphs
  ggplot(aes(y = value, x = ...1, group = model, col = model))+
  geom_line() +
  facet_wrap(~ metric, scales = "free") +
  # add theme
  theme_bw()+
  # add labels
  labs(title = "Comparing the Bayesian Negative Binomial model and the Standard Negative Binomial model",
       subtitle = "Comparison of four metrics with sample size n = 60, \u03B8 = 5",
       x = "Dataset number")
```

Below is a table comparing the metrics

```{r}
library(flextable)
s2_60 <- 
five_pnt5 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  group_by(metric,model) %>% 
  summarise(mean_val = mean(value)) %>% 
  spread(key = model, value = mean_val)  %>% 
  mutate(n = 60, theta = 5)


s2_60 %>% 
  mutate_if(is.numeric,round, 2) %>% 
  regulartable()
```
NB beats BNB

### Sample size n = 120

```{r}
# Read in the four time periods
ten_a5 <- read_csv("./model_results_pap/ten_year_5_metrics.csv")
# add mdtype column
ten_a5$model <- "NB"

ten_b5 <- read_csv("./model_results_pap/ten_year_5b_metrics.csv")
# add mdtype
ten_b5$model <- "BNB"
# combine the two
ten_pnt5 <- rbind(ten_a5, ten_b5)
head(ten_pnt5)
```

```{r, fig.width=8, fig.height=6}
# Long format
library(tidyr)
ten_pnt5 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  # Plot line graphs
  ggplot(aes(y = value, x = ...1, group = model, col = model))+
  geom_line() +
  facet_wrap(~ metric, scales = "free") +
  # add theme
  theme_bw()+
  # add labels
  labs(title = "Comparing the Bayesian Negative Binomial model and the Standard Negative Binomial model",
       subtitle = "Comparison of four metrics with sample size n = 120, \u03B8 = 5",
       x = "Dataset number")
```

Below is a table comparing the metrics

```{r}
library(flextable)
s2_120 <- 
ten_pnt5 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  group_by(metric,model) %>% 
  summarise(mean_val = mean(value)) %>% 
  spread(key = model, value = mean_val)  %>% 
  mutate(n = 120, theta = 5)


s2_120 %>% 
  mutate_if(is.numeric,round, 2) %>% 
  regulartable()
```

### Sample size n = 240

```{r}
# Read in the four time periods
twenty_a5 <- read_csv("./model_results_pap/twenty_year_5_metrics.csv")
# add mdtype column
twenty_a5$model <- "NB"

twenty_b5 <- read_csv("./model_results_pap/twenty_year_5b_metrics.csv")
# add mdtype
twenty_b5$model <- "BNB"
# combine the two
twenty_pnt5 <- rbind(twenty_a5, twenty_b5)
head(twenty_pnt5)
```

```{r, fig.width=8, fig.height=6}
# Long format
library(tidyr)
twenty_pnt5 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  # Plot line graphs
  ggplot(aes(y = value, x = ...1, group = model, col = model))+
  geom_line() +
  facet_wrap(~ metric, scales = "free") +
  # add theme
  theme_bw()+
  # add labels
  labs(title = "Comparing the Bayesian Negative Binomial model and the Standard Negative Binomial model",
       subtitle = "Comparison of four metrics with sample size n = 240, \u03B8 = 5",
       x = "Dataset number")
```

Below is a table comparing the metrics

```{r}
library(flextable)
s2_240 <- 
twenty_pnt5 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  group_by(metric,model) %>% 
  summarise(mean_val = mean(value)) %>% 
  spread(key = model, value = mean_val) %>% 
  mutate(n = 240, theta = 5)



s2_240 %>% 
  mutate_if(is.numeric,round, 2) %>% 
  regulartable()
```

### Sample size n = 360

```{r}
# Read in the four time periods
thirty_a5 <- read_csv("./model_results_pap/thirty_year_5_metrics.csv")
# add mdtype column
thirty_a5$model <- "NB"

thirty_b5 <- read_csv("./model_results_pap/thirty_year_5b_metrics.csv")
# add mdtype
thirty_b5$model <- "BNB"
# combine the two
thirty_pnt5 <- rbind(thirty_a5, thirty_b5)
head(thirty_pnt5)
```

```{r, fig.width=8, fig.height=6}
# Long format
library(tidyr)
thirty_pnt5 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  # Plot line graphs
  ggplot(aes(y = value, x = ...1, group = model, col = model))+
  geom_line() +
  facet_wrap(~ metric, scales = "free") +
  # add theme
  theme_bw()+
  # add labels
  labs(title = "Comparing the Bayesian Negative Binomial model and the Standard \nNegative Binomial model",
       subtitle = "Comparison of four metrics with sample size n = 360, \u03B8 = 5",
       x = "Dataset number")
```

Below is a table comparing the metrics

```{r}
library(flextable)
s2_360 <- 
thirty_pnt5 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  group_by(metric,model) %>% 
  summarise(mean_val = mean(value)) %>% 
  spread(key = model, value = mean_val) %>% 
  mutate(n = 360, theta = 5)



s2_360 %>% 
  mutate_if(is.numeric,round, 2) %>% 
  regulartable()
```

NB beats BNB
## Scenario 3 (Theta = 10)

### Sample size n = 60

```{r}
# Read in the four time periods
five_a10 <- read_csv("./model_results_pap/five_year_10_metrics.csv")
# add mdtype column
five_a10$model <- "NB"

five_b10 <- read_csv("./model_results_pap/five_year_10b_metrics.csv")
# add mdtype
five_b10$model <- "BNB"
# combine the two
five_pnt10 <- rbind(five_a10, five_b10)
head(five_pnt10)
```

```{r, fig.width=8, fig.height=6}
# Long format
library(tidyr)
five_pnt10 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  # Plot line graphs
  ggplot(aes(y = value, x = ...1, group = model, col = model))+
  geom_line() +
  facet_wrap(~ metric, scales = "free") +
  # add theme
  theme_bw()+
  # add labels
  labs(title = "Comparing the Bayesian Negative Binomial model and the Standard Negative Binomial model",
       subtitle = "Comparison of four metrics with sample size n = 60, \u03B8 = 10",
       x = "Dataset number")
```

Below is a table comparing the metrics

```{r}
library(flextable)

s3_60 <- 
five_pnt10 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  group_by(metric,model) %>% 
  summarise(mean_val = mean(value)) %>% 
  spread(key = model, value = mean_val) %>% 
  mutate(n = 60, theta = 10)


s3_60 %>% 
  mutate_if(is.numeric,round, 2) %>% 
  regulartable()
```

### Sample size n = 120

```{r}
# Read in the four time periods
ten_a10 <- read_csv("./model_results_pap/ten_year_10_metrics.csv")
# add mdtype column
ten_a10$model <- "NB"

ten_b10 <- read_csv("./model_results_pap/ten_year_10b_metrics.csv")
# add mdtype
ten_b10$model <- "BNB"
# combine the two
ten_pnt10 <- rbind(ten_a10, ten_b10)
head(ten_pnt10)
```

```{r, fig.width=8, fig.height=6}
# Long format
library(tidyr)
ten_pnt10 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  # Plot line graphs
  ggplot(aes(y = value, x = ...1, group = model, col = model))+
  geom_line() +
  facet_wrap(~ metric, scales = "free") +
  # add theme
  theme_bw()+
  # add labels
  labs(title = "Comparing the Bayesian Negative Binomial model and the Standard Negative Binomial model",
       subtitle = "Comparison of four metrics with sample size n = 120, \u03B8 = 10",
       x = "Dataset number")
```

Below is a table comparing the metrics

```{r}
library(flextable)

s3_120 <- 
ten_pnt10 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  group_by(metric,model) %>% 
  summarise(mean_val = mean(value)) %>% 
  spread(key = model, value = mean_val) %>% 
  mutate(n = 120, theta = 10)


s3_120 %>% 
  mutate_if(is.numeric,round, 2) %>% 
  regulartable()
```
NB beats BNB

### Sample size n = 240

```{r}
# Read in the four time periods
twenty_a10 <- read_csv("./model_results_pap/twenty_year_10_metrics.csv")
# add mdtype column
twenty_a10$model <- "NB"

twenty_b10 <- read_csv("./model_results_pap/twenty_year_10b_metrics.csv")
# add mdtype
twenty_b10$model <- "BNB"
# combine the two
twenty_pnt10 <- rbind(twenty_a10, twenty_b10)
head(twenty_pnt10)
```

```{r, fig.width=8, fig.height=6}
# Long format
library(tidyr)
twenty_pnt10 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  # Plot line graphs
  ggplot(aes(y = value, x = ...1, group = model, col = model))+
  geom_line() +
  facet_wrap(~ metric, scales = "free") +
  # add theme
  theme_bw()+
  # add labels
  labs(title = "Comparing the Bayesian Negative Binomial model and the Standard Negative Binomial model",
       subtitle = "Comparison of four metrics with sample size n = 240, \u03B8 = 10",
       x = "Dataset number")
```

Below is a table comparing the metrics

```{r}
library(flextable)
s3_240 <- 
twenty_pnt10 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  group_by(metric,model) %>% 
  summarise(mean_val = mean(value)) %>% 
  spread(key = model, value = mean_val) %>% 
  mutate(n = 240, theta = 10)



s3_240 %>% 
  mutate_if(is.numeric,round, 2) %>% 
  regulartable()
```

### Sample size n = 360

```{r}
# Read in the four time periods
thirty_a10 <- read_csv("./model_results_pap/thirty_year_10_metrics.csv")
# add mdtype column
thirty_a10$model <- "NB"

thirty_b10 <- read_csv("./model_results_pap/thirty_year_10b_metrics.csv")
# add mdtype
thirty_b10$model <- "BNB"
# combine the two
thirty_pnt10 <- rbind(thirty_a10, thirty_b10)
head(thirty_pnt10)
```

```{r, fig.width=8, fig.height=6}
# Long format
library(tidyr)
thirty_pnt10 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  # Plot line graphs
  ggplot(aes(y = value, x = ...1, group = model, col = model))+
  geom_line() +
  facet_wrap(~ metric, scales = "free") +
  # add theme
  theme_bw()+
  # add labels
  labs(title = "Comparing the Bayesian Negative Binomial model and the Standard Negative Binomial model",
       subtitle = "Comparison of four metrics with sample size n = 360, \u03B8 = 10",
       x = "Dataset number")
```

Below is a table comparing the metrics

```{r}
library(flextable)

s3_360 <- 
thirty_pnt10 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  group_by(metric,model) %>% 
  summarise(mean_val = mean(value)) %>% 
  spread(key = model, value = mean_val)%>% 
  mutate(n = 360, theta = 10)



s3_360 %>% 
  mutate_if(is.numeric,round, 2) %>% 
  regulartable()
```

## Scenario 4 (Theta = 100)

### Sample size n = 60

```{r}
# Read in the four time periods
five_a100 <- read_csv("./model_results_pap/five_year_100_metrics.csv")
# add mdtype column
five_a100$model <- "NB"

five_b100 <- read_csv("./model_results_pap/five_year_100b_metrics.csv")
# add mdtype
five_b100$model <- "BNB"
# combine the two
five_pnt100 <- rbind(five_a100, five_b100)
head(five_pnt100)
```

```{r, fig.width=8, fig.height=6}
# Long format
library(tidyr)
five_pnt100 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  # Plot line graphs
  ggplot(aes(y = value, x = ...1, group = model, col = model))+
  geom_line() +
  facet_wrap(~ metric, scales = "free") +
  # add theme
  theme_bw()+
  # add labels
  labs(title = "Comparing the Bayesian Negative Binomial model and the Standard Negative Binomial model",
       subtitle = "Comparison of four metrics with sample size n = 60, \u03B8 = 100",
       x = "Dataset number")
```

Below is a table comparing the metrics

```{r}
library(flextable)

s4_60 <- 
five_pnt100 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  group_by(metric,model) %>% 
  summarise(mean_val = mean(value)) %>% 
  spread(key = model, value = mean_val) %>% 
  mutate(n = 60, theta = 100)


s4_60 %>% 
  mutate_if(is.numeric,round, 2) %>% 
  regulartable()
```

### Sample size n = 120

```{r}
# Read in the four time periods
ten_a100 <- read_csv("./model_results_pap/ten_year_100_metrics.csv")
# add mdtype column
ten_a100$model <- "NB"

ten_b100 <- read_csv("./model_results_pap/ten_year_100b_metrics.csv")
# add mdtype
ten_b100$model <- "BNB"
# combine the two
ten_pnt100 <- rbind(ten_a100, ten_b100)
head(ten_pnt100)
```

```{r, fig.width=8, fig.height=6}
# Long format
library(tidyr)
ten_pnt100 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  # Plot line graphs
  ggplot(aes(y = value, x = ...1, group = model, col = model))+
  geom_line() +
  facet_wrap(~ metric, scales = "free") +
  # add theme
  theme_bw()+
  # add labels
  labs(title = "Comparing the Bayesian Negative Binomial model and the Standard Negative Binomial model",
       subtitle = "Comparison of four metrics with sample size n = 120, \u03B8 = 100",
       x = "Dataset number")
```

Below is a table comparing the metrics

```{r}
library(flextable)
s4_120 <- 
ten_pnt100 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  group_by(metric,model) %>% 
  summarise(mean_val = mean(value)) %>% 
  spread(key = model, value = mean_val) %>% 
  mutate(n = 120, theta = 100)


s4_120 %>%
  mutate_if(is.numeric,round, 2) %>% 
  regulartable()
```

### Sample size n = 240

```{r}
# Read in the four time periods
twenty_a100 <- read_csv("./model_results_pap/twenty_year_100_metrics.csv")
# add mdtype column
twenty_a100$model <- "NB"

twenty_b100 <- read_csv("./model_results_pap/twenty_year_100b_metrics.csv")
# add mdtype
twenty_b100$model <- "BNB"
# combine the two
twenty_pnt100 <- rbind(twenty_a100, twenty_b100)
head(five_pnt100)
```

```{r, fig.width=8, fig.height=6}
# Long format
library(tidyr)
twenty_pnt10 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  # Plot line graphs
  ggplot(aes(y = value, x = ...1, group = model, col = model))+
  geom_line() +
  facet_wrap(~ metric, scales = "free") +
  # add theme
  theme_bw()+
  # add labels
  labs(title = "Comparing the Bayesian Negative Binomial model and the Standard Negative Binomial model",
       subtitle = "Comparison of four metrics with sample size n = 240, \u03B8 = 100",
       x = "Dataset number")
```

Below is a table comparing the metrics

```{r}
library(flextable)
s4_240 <- 
twenty_pnt10 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  group_by(metric,model) %>% 
  summarise(mean_val = mean(value)) %>% 
  spread(key = model, value = mean_val)%>% 
  mutate(n = 240, theta = 100)


s4_240 %>% 
  mutate_if(is.numeric,round, 2) %>% 
  regulartable()
```

### Sample size n = 360

```{r}
# Read in the four time periods
thirty_a100 <- read_csv("./model_results_pap/thirty_year_100_metrics.csv")
# add mdtype column
thirty_a100$model <- "NB"

thirty_b100 <- read_csv("./model_results_pap/thirty_year_100b_metrics.csv")
# add mdtype
thirty_b100$model <- "BNB"
# combine the two
thirty_pnt100 <- rbind(thirty_a100, thirty_b100)
head(thirty_pnt100)
```

```{r, fig.width=8, fig.height=6}
# Long format
library(tidyr)
thirty_pnt100 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  # Plot line graphs
  ggplot(aes(y = value, x = ...1, group = model, col = model))+
  geom_line() +
  facet_wrap(~ metric, scales = "free") +
  # add theme
  theme_bw()+
  # add labels
  labs(title = "Comparing the Bayesian Negative Binomial model and the Standard Negative Binomial model",
       subtitle = "Comparison of four metrics with sample size n = 360, \u03B8 = 100",
       x = "Dataset number")
```

Below is a table comparing the metrics

```{r}
library(flextable)
s4_360 <- 
thirty_pnt100 %>% 
  pivot_longer(cols = rmse_train:bias_test, names_to = "metric",
               values_to = "value") %>% 
  group_by(metric,model) %>% 
  summarise(mean_val = mean(value)) %>% 
  spread(key = model, value = mean_val)%>% 
  mutate(n = 360, theta = 100)


s4_360 %>% 
  mutate_if(is.numeric,round, 2) %>% 
  regulartable()
```


## Combine all simulation results
```{r}
# combine data
final_sim <- rbind(s1_60, s1_120, s1_240, s1_360,
                   s2_60, s2_120, s2_240, s2_360,
                   s3_60, s3_120, s3_240, s3_360,
                   s4_60, s4_120, s4_240, s4_360)

# write out file for future
write.csv(final_sim, "paper_sim_results_pap.csv")
```


```{r}
# Plot
final_sim %>% 
  filter(n == 60) %>% 
  pivot_longer(BNB:NB, names_to = "model", values_to = "value") %>% 
  mutate(label = ifelse(metric == "bias_test", paste("(a)","       Bias on test sets"),
                                                     ifelse(metric == "mase_test", paste("(b)",
                                                                                         "       MASE on test sets"),
                                                            ifelse(metric == "rmse_test",
                                                                   paste("(c)","       RMSE on test sets"), paste("(d)", "       RMSE on training sets"))))) %>% 
  ggplot(aes(x = theta, y = value, group = model, col = model)) +
  geom_line() +
  facet_wrap(~label, scales = "free")+# add theme
  theme_bw()+
  # add labels
  labs(title = "Comparing the Bayesian Negative Binomial model and the Standard Negative Binomial model",
       subtitle = "Comparison of four metrics with sample size = 60",
       x = "Dispersion parameter \u03B8")


```

```{r}
# Plot
final_sim %>% 
  filter(n == 120) %>% 
  pivot_longer(BNB:NB, names_to = "model", values_to = "value") %>% 
  mutate(label = ifelse(metric == "bias_test", paste("(a)","       Bias on test sets"),
                                                     ifelse(metric == "mase_test", paste("(b)",
                                                                                         "       MASE on test sets"),
                                                            ifelse(metric == "rmse_test",
                                                                   paste("(c)","       RMSE on test sets"), paste("(d)", "       RMSE on training sets"))))) %>% 
  ggplot(aes(x = theta, y = value, group = model, col = model)) +
  geom_line() +
  facet_wrap(~label, scales = "free")+# add theme
  theme_bw()+
  # add labels
  labs(title = "Comparing the Bayesian Negative Binomial model and the Standard Negative Binomial model",
       subtitle = "Comparison of four metrics with sample size = 120",
       x = "Dispersion parameter \u03B8")
```

```{r}
# Plot
final_sim %>% 
  filter(n == 240) %>% 
  pivot_longer(BNB:NB, names_to = "model", values_to = "value") %>% 
  mutate(label = ifelse(metric == "bias_test", paste("(a)","       Bias on test sets"),
                                                     ifelse(metric == "mase_test", paste("(b)",
                                                                                         "       MASE on test sets"),
                                                            ifelse(metric == "rmse_test",
                                                                   paste("(c)","       RMSE on test sets"), paste("(d)", "       RMSE on training sets"))))) %>% 
  ggplot(aes(x = theta, y = value, group = model, col = model)) +
  geom_line() +
  facet_wrap(~label, scales = "free")+# add theme
  theme_bw()+
  # add labels
  labs(title = "Comparing the Bayesian Negative Binomial model and the Standard Negative Binomial model",
       subtitle = "Comparison of four metrics with sample size = 240",
       x = "Dispersion parameter \u03B8")
```

```{r}
# Plot
final_sim %>% 
  filter(n == 360) %>% 
  pivot_longer(BNB:NB, names_to = "model", values_to = "value") %>% 
  mutate(label = ifelse(metric == "bias_test", paste("(a)","       Bias on test sets"),
                                                     ifelse(metric == "mase_test", paste("(b)",
                                                                                         "       MASE on test sets"),
                                                            ifelse(metric == "rmse_test",
                                                                   paste("(c)","       RMSE on test sets"), paste("(d)", "       RMSE on training sets"))))) %>% 
  ggplot(aes(x = theta, y = value, group = model, col = model)) +
  geom_line() +
  facet_wrap(~label, scales = "free")+# add theme
  theme_bw()+
  # add labels
  labs(title = "Comparing the Bayesian Negative Binomial model and the Standard Negative Binomial model",
       subtitle = "Comparison of four metrics with sample size = 360",
       x = "Dispersion parameter \u03B8")
```


# On real data

```{r}
# Negbinner
negbinner2 <- function(x, prop = 0.8){
  
  # create training and test sets
  # set seed
  set.seed(456)
  
  n = length(x$count)
  trainIndex <- round(prop*n)
  # Create the data sets
  fireTrain <- x[1:trainIndex,]
  fireTest  <- x[(trainIndex+1):n,]
  
  # Fit model on training set
  
  glmNB <- MASS::glm.nb(count ~ mean_max_temp +
                           mean_rainfall, data = fireTrain,
                        link = "log")
  # Predict on training set
  predictions_train <- predict(glmNB,
                         newdata = fireTrain, type = "response")
  # Predict on testing set
  predictions_test <- predict(glmNB,
                         newdata = fireTest, type = "response")
  # get the rmse
  train_rmse <- caret::RMSE(round(predictions_train),fireTrain$count)
  
  test_rmse <- caret::RMSE(round(predictions_test),fireTest$count)
  
  # get the MASE
  test_mase <- Metrics::mase(actual = fireTest$count,
                             predicted = round(predictions_test))
  
  # Get the bias
  test_bias <- Metrics::bias(actual = fireTest$count,
                             predicted = round(predictions_test))
  # Dispersion parameter
  
  df = cbind(rmse_train = train_rmse, rmse_test = test_rmse, mase_test = test_mase,
        bias_test = test_bias, n = n, prop = prop)
  
  df
  
}
```

```{r}
stanbinner2 <- function(x, prop = 0.8){
  
  # create training and test sets
  # set seed
  set.seed(456)
  n = length(x$count)
  
  # Add time by month index
  x$time <- rep(1:12, length.out = n)
  
  
  trainIndex <- round(prop*n)
  # Create the datasets
  fireTrain <- x[1:trainIndex,]
  fireTest  <- x[(trainIndex+1):n,]
  
  # Add prior means
  
  get_prior_means <- function(x){
    library(dplyr)
    x %>% group_by(month) %>% 
      summarize(count_mean = mean(count))  %>% 
      data.frame()
  }
  
  p_means = get_prior_means(fireTrain)
  
  # Join means to train data
  fireTrain2 <- fireTrain %>% 
    inner_join(p_means, by = "month")
  
  # Join means to test data
  fireTest2 <- fireTest %>% 
    inner_join(p_means, by = "month")
  
  
  # Fit model on training set
  
  stanNB <- rstanarm::stan_glm.nb(count ~  mean_max_temp+
                                  mean_rainfall + count_mean,
                                 data = fireTrain2,
                                 link = "log")
  # Predict on training set
  predictions_train <- predict(stanNB,
                               newdata = fireTrain2, type = "response")
  # Predict on testing set
  predictions_test <- predict(stanNB,
                              newdata = fireTest2, type = "response")
  # get the rmse
  train_rmse <- caret::RMSE(round(predictions_train),fireTrain2$count)
  
  test_rmse <- caret::RMSE(round(predictions_test),fireTest2$count)
  
  # get the MASE
  test_mase <- Metrics::mase(actual = fireTest2$count,
                             predicted = round(predictions_test))
  # Get the bias
  test_bias <- Metrics::bias(actual = fireTest2$count,
                             predicted = round(predictions_test))
  # Dispersion parameter
  
  df = cbind(rmse_train = train_rmse, rmse_test = test_rmse, mase_test = test_mase,
        bias_test = test_bias, n = n, prop = prop)
  
  df
}
```

```{r, message=FALSE}
# Script to fit models on data
library(MASS)
library(stsm)
# Load libraries ----
library(rstanarm)
library(brms)  # for models
library(bayesplot)
library(ggplot2)
library(dplyr)
library(tidybayes)
library(modelr) 
#library(tidyverse)
library(caret)
library(readr)
library(purrr)
library(parallel)
# read in the data
series_data <- read_csv("fire_data_2000-18.csv")

# Set seed
set.seed(76568)

# Standard NB
nb_result80 <- negbinner2(series_data, prop = 0.8)
nb_result90 <- negbinner2(series_data, prop = 0.9)
nb_result95 <- negbinner2(series_data, prop = 0.95)

# Bayesian NB
bnb_result80 <- stanbinner2(series_data, prop = 0.8)
bnb_result90 <- stanbinner2(series_data, prop = 0.9)
bnb_result95 <- stanbinner2(series_data, prop = 0.95)
```


```{r}
rbind(data.frame(nb_result90),data.frame(bnb_result90)) %>% 
  data.frame() %>% 
  mutate_if(is.numeric, round, 2)
```

```{r}
rbind(bnb_result80,bnb_result90, bnb_result95) %>% 
  data.frame()
```


```{r}
# prediction intervals
intervals_bnb <- predictive_interval(stanNB, newdata = fireTest2, prob = 0.9)
# add test data
preds_intervals <- cbind(intervals_bnb, fireTest2$count)
# Write
write.csv(preds_intervals, "prediction_intervals_pap.csv")
```

```{r}
# Review prediction intervals
pred_int <- read.csv("prediction_intervals_pap.csv")
# Rename variables
pred_int$lower <-  pred_int$X5.
pred_int$upper <- pred_int$X95.
pred_int$actual <-  pred_int$X.1
pred_int <- pred_int[,-c(2,3,4)]
head(pred_int)
```

```{r}
# plot a prediction interval curve
pred_int %>% 
  pivot_longer(lower:actual, names_to = "interval",
               values_to = "Count") %>% 
  ggplot(aes(x = X, y = Count, group = interval, col = interval)) +
  geom_line() +
  labs(title = "Prediction intervals of the BNB model compared to the actuals",
       subtitle = "Values obtained from the predictions on the testing dataset at 0.9 desired probability mass", x = "Index of value")+
  theme_bw()
```


# Suggestions for further research

Other suggestions for further research are outlined below.
1. Extend the models in our proposed framework to account for more general flex plans.
For example:

* Having multiple lines of benefits with different reimbursement functions. This
will require that each plan member has multiple correlated health statuses for
each line of benefit.

* Allowing for dependents’ coverage. A simple way of incorporating family or couples
coverage in addition to single coverage is to include a family status factor in
each individual’s health status.

* Allowing for the group size or group demographics to change each year.

2. Refine the proposed models. For example:

* Accounting for moral hazard in the claim model.

* Further dividing the risk classification groups in the health status model to include
more variables in addition to age, such as gender and geographical location.
The health deterioration rate,, may also vary with age and through time; i.e.,
an x year old individual’s health deterioration rate in year t can be t,x.

* Accounting for biased intuitions in each plan member’s estimate of their own
health status (i.e., whether particular individuals tend to be more optimistic
or pessimistic about their estimated health status), so that the mean of t,j is
nonzero. The accuracy of intuition, , can also depend on the individual and
through time, so that we have t,j as the variance of t,j in Equation (2.6).

3. Explore alternative models within our framework. For example:

* Using an alternative objective function in the constrained optimization problem.
Examples include:




